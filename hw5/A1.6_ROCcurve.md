# Q 1.6

1.6 Plot the 3 values of Recall and Precision for each of the chatbot versions on the ROC curve. Discuss which one would you pick as your final chatbot and why.


# A 1.6

Receiver operating characteristic curve (ROC Curve):

- True Positive Rate as X, False Positive Rate as Y

- True Positive Rate (TPR) ("Hit Rate") `TPR = TP / (TP + FN)`

- False Positive Rate (FPR) ("False Alarm Rate") `FPR = FP / (FP + TN)`


### Test 1

- TPR = `TP / (TP + FN)` = 7 / (7+3) = 0.7
- FPR = `FP / (FP + TN)` = 3 / (3+7) = 0.3

	- `True Positive (TP)` = 7
	- `False Positive (FP)` = 3
	- `False Negative (FN)` = 3
	- `True Negative (TN)` = 7
	- `Accuracy (ACC) = (TP+TN) / All` = (7+7) / 20 = 70%
	- `Precision (P) = TP / (TP + FP)` = 7 / (7+3) = 70%
	- `Recall (R) = TP / (TP + FN)` = 7 / (7+3) = 70%
	
### Test 2

- TPR = `TP / (TP + FN)` = 10 / (10+6) = 0.625
- FPR = `FP / (FP + TN)` = 5/ (5+9) =~ 0.36

	- `True Positive (TP)` = 10
	- `False Positive (FP)` = 5
	- `False Negative (FN)` = 6
	- `True Negative (TN)` = 9
	- `Accuracy (ACC) = (TP+TN) / All` = (10+9) / 30 = 63%
	- `Precision (P) = TP / (TP + FP)` = 10 / (10+5) = 66%
	- `Recall (R) = TP / (TP + FN)` = 10 / (10+6) = 62.5%

### Test 3

- TPR = `TP / (TP + FN)` = 12 / (12+6) =~ 0.67
- FPR = `FP / (FP + TN)` = 3 / (3+9) = 0.25

	- `True Positive (TP)` = 12
	- `False Positive (FP)` = 3
	- `False Negative (FN)` = 6
	- `True Negative (TN)` = 9
	- `Accuracy (ACC) = (TP+TN) / All` = (12+9) / 30 = 70%
	- `Precision (P) = TP / (TP + FP)` = 12 / (12+3) = 80%
	- `Recall (R) = TP / (TP + FN)` = 12 / (12+6) = 66%

### ROC Curve

![roc curve](https://github.com/linnnes/CI2017/blob/master/hw5/A1.5_FSM_and_Code/roccurve.png?raw=true)


Conslusion:

The one I should picked for my chatbot is the first one - the one located at (0.625, 0.36).

Because the left top is the most ideal situationâ€” "Perfect Classification":

>The best possible prediction method would yield a point in the upper left corner or coordinate (0,1) of the ROC space, representing 100% sensitivity (no false negatives) and 100% specificity (no false positives). The (0,1) point is also called a perfect classification. 
> [Receiver Operating Characteristics (ROC-surve)](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)

And (0.625, 0.36) is the one that most close to the Perfect Classification.

Although (0.7, 0.3) could be also put in consideration, it actually has higher False Positive Rate. The ideal case on False Positive Rate would be as lower as possible, namely, all the positive conditions are being almost predicted.

Meanwhile, the True Positive Rate definety could be better, and to be more close to the perfect "1". In order to do that, we could either improve the positive prediction, or, decrease the False Negative. In order words, the classifier should be able to predict all the negative conditions as predicted negative conditions.

